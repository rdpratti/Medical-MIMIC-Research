{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3a8acb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><font color=\"black\"><h1><left>Scrub MIMIC ICU Data for Intestinal Conditions</left></h1></font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40095d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17845bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\Education\\DataScience\\CCSU-Data-Science\\Data-Mining-And-Predictive-Analytics\\Data-532\\Data\\\\'\n",
    "file1 = path + 'pd_notes.snappy.parquet'\n",
    "file2 = path + 'discharge_notes.snappy.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "486a65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions:  2694\n",
      "discharge-notes:  6274\n"
     ]
    }
   ],
   "source": [
    "# How many notes from each file\n",
    "pn_notes = pd.read_parquet(file1,engine='auto',use_nullable_dtypes=True)\n",
    "print('admissions: ',len(pn_notes['hadm_id'].unique()))\n",
    "discharge_notes = pd.read_parquet(file2,engine='auto',use_nullable_dtypes=True)\n",
    "print('discharge-notes: ',len(discharge_notes['hadm_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6590deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22554, 22210, 16203, 30477]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ms [**Known lastname 406**] is a 24 yo F with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24YOF w/ ESRD, HTN started on OD this week. Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Admitted to SICU under MICU service at 0620 th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24yo female pt with h/o ESRD on regular HD ( t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NURSING MICU NOTE 7P-7A\n",
       "\n",
       "PT [**Name (NI) 577**...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1  Ms [**Known lastname 406**] is a 24 yo F with ...\n",
       "2  24YOF w/ ESRD, HTN started on OD this week. Pr...\n",
       "3  Admitted to SICU under MICU service at 0620 th...\n",
       "4  24yo female pt with h/o ESRD on regular HD ( t...\n",
       "5  NURSING MICU NOTE 7P-7A\n",
       "\n",
       "PT [**Name (NI) 577**..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 5 notes and their length to guarantee format before processing\n",
    "pn_notes.columns \n",
    "note_len = [len(x) for x in pn_notes['text']]\n",
    "print(note_len[1:5])\n",
    "pn_notes.iloc[[1,2,3,4,5],[17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d42c3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admission_type\n",
       "EMERGENCY    2624\n",
       "URGENT         70\n",
       "Name: hadm_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note counts by admission type\n",
    "pn_notes.groupby('admission_type')['hadm_id'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43100ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write input Dictionary:  102\n"
     ]
    }
   ],
   "source": [
    "def store_med_tags(df):\n",
    "    \n",
    "    import operator\n",
    "\n",
    "    tags_dict = {}\n",
    "    for row in df.itertuples():\n",
    "        tags = findall_med_tags(row.text)\n",
    "        if tags is not None:\n",
    "            for tag in tags:\n",
    "                temp_tag = str(tag)\n",
    "#                if len(tags) > 0 :\n",
    "#                    print('tag: ',tags)\n",
    "                if temp_tag in tags_dict.keys():\n",
    "                    tags_dict[temp_tag] += 1\n",
    "                else:\n",
    "                    tags_dict[temp_tag] = 1\n",
    "    \n",
    "    sorted_d = dict( sorted(tags_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "#    print('Dictionary in descending order by value : ',len(sorted_d))\n",
    "     \n",
    "    return sorted_d\n",
    "#    return sorted_d\n",
    "\n",
    "\n",
    "def findall_med_tags(note_data):\n",
    "\n",
    "# https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/\n",
    "    #print('in data length: ', len(note_data))\n",
    "    \n",
    "    regex2 = r\"(\\[(.+?)\\])\"\n",
    "    \n",
    "    note_data = re.sub(r'\\[.*?:.*?\\]', ' ', note_data)\n",
    "    note_data = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', ' ', note_data)\n",
    "    note_data = re.sub(r'\\s{2,99}', ' ', note_data)\n",
    "    note_data = re.sub(r'\\n', ' ', note_data)\n",
    "#   note_data = re.sub(regex, ' ', note_data)\n",
    "    note_data = note_data.upper()\n",
    "    tags= re.findall(regex2, note_data)\n",
    "    \n",
    "#    if len(tags) > 0 :\n",
    "#        print('tag length: ', len(tags))\n",
    "#        print('tags:\\n ', tags)\n",
    "        \n",
    "    return tags\n",
    "\n",
    "\n",
    "def write_dict_csv(outfile, adict):\n",
    "\n",
    "    \n",
    "    import csv\n",
    "    print('Write input Dictionary: ',len(adict.keys()))\n",
    "    field_names = ['word','count']\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(outfile, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for key in adict:\n",
    "#            if adict[key] > 300:\n",
    "            writer.writerow({'word': key, 'count': adict[key]})\n",
    "    csvfile.close()   \n",
    "    return\n",
    "    \n",
    "file2 = path + 'big_notes_tags_4-7-23.csv'\n",
    "adict = store_med_tags(pn_notes)\n",
    "if adict is not None:\n",
    "    write_dict_csv(file2, adict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b48c9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine to remove unneccessary characters\n",
    "import re\n",
    "\n",
    "def preprocess1(x):\n",
    "    \n",
    "#    print('in2a: ', 'x length ', len(x),  '', x[0:20])\n",
    "    y = re.sub('\\\\[(.*?)\\\\]', '', x)\n",
    "#    print('in2b: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('[0-9]+\\.', '', y)  # remove 1.2. since the segmenter segments based on this\n",
    "#    print('in2c: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('dr\\.', 'doctor', y)\n",
    "#    print('in2d: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('m\\.d\\.', 'md', y)\n",
    "#    print('in2e: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('admission date:', '', y)\n",
    "#    print('in2f: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('discharge date:', '', y)\n",
    "#    print('in2g: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('--|__|==', ' ', y)\n",
    "    \n",
    "     # remove, digits, spaces\n",
    "#    print('in2h: ', 'y length ', len(y),  ' ', y[0:20])\n",
    "    y = y.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "#    print('in2i: ', 'y length ', len(y),  ' ', y[0:20])\n",
    "    y = \" \".join(y.split())\n",
    "#    print('in2j: ', 'y length ', len(y),  ' ', y[0:20])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75e18430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process each note, call above function, get rid of line feeds, and make lowercase\n",
    "from tqdm import tqdm, trange \n",
    "def preprocessing(df_less_n):\n",
    "#    print('in2: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].fillna(' ')\n",
    "#    print('in3: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].str.replace('\\n', ' ')\n",
    "#    print('in4: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].str.replace('\\r', ' ')\n",
    "#    print('in5: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].apply(str.strip)\n",
    "#    print('in6: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].str.lower()\n",
    "#    print('in7: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].apply(lambda x: preprocess1(x))\n",
    "#    print('in8: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    return df_less_n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b255efa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    nursing a-p see adm hx for pmh & events leadin...\n",
      "1    ms is a yo f with lupus since age , with esrd ...\n",
      "Name: text, dtype: object\n",
      "0    date of birth: sex: m service: medicine allerg...\n",
      "1    date of birth: sex: m service: cardiothoracic ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# run preprocess for discharge and adm notes\n",
    "import string\n",
    "discharge_notes = preprocessing(discharge_notes)\n",
    "pn_notes = preprocessing(pn_notes)\n",
    "# print first 2 texts columns in each dataset as a sanity check after cleanup\n",
    "print(pn_notes[0:2].text[0:10])\n",
    "print(discharge_notes[0:2].text[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ec0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E://Education//DataScience/CCSU-Data-Science/Data-Mining-And-Predictive-Analytics/Data-532/Data/'\n",
    "pn_notes.to_parquet(path + 'pd_notes_clean.snappy.parquet',compression='snappy',index=None)  \n",
    "discharge_notes.to_parquet(path + 'discharge_notes_clean.snappy.parquet',compression='snappy',index=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d343bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os\n",
    "s3 = boto3.resource('s3')\n",
    "path = 'E://Education//DataScience/CCSU-Data-Science/Data-Mining-And-Predictive-Analytics/Data-532/Data/'\n",
    "f1name = 'pd_notes_clean.snappy.parquet'\n",
    "f2name = 'discharge_notes_clean.snappy.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e267056",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'MIMIC/Data/' \n",
    "S3_path = subdir + f1name\n",
    "out_file = path + f1name\n",
    "s3.meta.client.upload_file(out_file, 'depratti-masters-thesis', S3_path)\n",
    "S3_path = subdir + f2name\n",
    "out_file = path + f2name\n",
    "s3.meta.client.upload_file(out_file, 'depratti-masters-thesis', S3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298a56fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pn_notes shape:  (2694, 19)\n",
      "pn_notes columns:  Index(['subject_id', 'hadm_id', 'icd9_codes', 'primary_icd9_code',\n",
      "       'primary_icd10_code', 'stay_hours', 'admittime', 'dischtime',\n",
      "       'deathtime', 'admission_type', 'insurance', 'language', 'religion',\n",
      "       'marital_status', 'ethnicity', 'diagnosis', 'ethnic_group', 'text',\n",
      "       'note_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('pn_notes shape: ', pn_notes.shape)\n",
    "print('pn_notes columns: ', pn_notes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bd028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
