{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a3a8acb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><font color=\"black\"><h1><left>Scrub MIMIC ICU Data for Intestinal Conditions</left></h1></font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40095d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17845bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Education/CCSU-Thesis-2024/Data/'\n",
    "file1 = path + 'pd_notes.snappy3.parquet'\n",
    "file2 = path + 'discharge_notes.snappy3.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "486a65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "admissions:  5379\n",
      "discharge-notes:  5359\n",
      "avg_pd_notes_per_admiss 1.0\n"
     ]
    }
   ],
   "source": [
    "# How many notes from each file\n",
    "pn_notes = pd.read_parquet(file1,engine='auto',dtype_backend='numpy_nullable')\n",
    "print('admissions: ',len(pn_notes['hadm_id'].unique()))\n",
    "discharge_notes = pd.read_parquet(file2,engine='auto',dtype_backend='numpy_nullable')\n",
    "print('discharge-notes: ',len(discharge_notes['hadm_id'].unique()))\n",
    "print('avg_pd_notes_per_admiss', len(pn_notes)/len(pn_notes['hadm_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2035dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   primary_icd10_code  totals\n",
      "0              A41.51     151\n",
      "1               A41.9     881\n",
      "2               I21.4     950\n",
      "3              I25.10    1216\n",
      "4               I34.0      74\n",
      "5               I35.2     155\n",
      "6              I50.23      92\n",
      "7               I50.9     301\n",
      "8               J18.9     324\n",
      "9               J69.0     348\n",
      "10             J96.00     625\n",
      "11              N17.9     262\n"
     ]
    }
   ],
   "source": [
    "# This identifies that 52 admissions do not have discharge notes\n",
    "import pandasql as ps\n",
    "\n",
    "qintsl = pn_notes[['primary_icd10_code', 'hadm_id']]\n",
    "qints2 = discharge_notes[['subject_id', 'hadm_id']]\n",
    "# print(qintsl.dtypes)\n",
    "q1 = \"\"\"SELECT a.primary_icd10_code, count(distinct a.hadm_id) as totals FROM qintsl a \n",
    "        group by a.primary_icd10_code\"\"\"  \n",
    "#        WHERE NOT EXISTS (SELECT *\n",
    "#                  FROM qints2 b \n",
    "#                  where a.subject_id = b.subject_id \n",
    "#                  AND a.hadm_id = b.hadm_id)\n",
    "#      \"\"\"\n",
    "\n",
    "p1 = ps.sqldf(q1, locals())\n",
    "print(p1)\n",
    "#print('Missing discharge notes count', len(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6590deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'hadm_id', 'text', 'note_length', 'primary_icd9_code',\n",
      "       'primary_icd10_code', 'icd_category', 'stay_days', 'admission_type',\n",
      "       'admittime', 'dischtime', 'deathtime', 'insurance', 'language',\n",
      "       'religion', 'marital_status', 'ethnicity', 'diagnosis', 'ethnic_group'],\n",
      "      dtype='object')\n",
      "[7912, 9896, 11662, 4894]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ccu npn\n",
       "s- having cpain left, l shoulder, arm,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADMISSION NOTE\n",
       "87 YR OLD MAN WITH H/O CAD, CVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCU Progress Note:\n",
       "\n",
       "This is a 58 yr old male P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nsg Adm note\n",
       "Mr. [**Known lastname 185**] is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nursing Admission Note 0700-1900.\n",
       "Pt transfere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "1  ccu npn\n",
       "s- having cpain left, l shoulder, arm,...\n",
       "2  ADMISSION NOTE\n",
       "87 YR OLD MAN WITH H/O CAD, CVA...\n",
       "3  CCU Progress Note:\n",
       "\n",
       "This is a 58 yr old male P...\n",
       "4  Nsg Adm note\n",
       "Mr. [**Known lastname 185**] is a...\n",
       "5  Nursing Admission Note 0700-1900.\n",
       "Pt transfere..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 5 notes and their length to guarantee format before processing\n",
    "print(pn_notes.columns) \n",
    "note_len = [len(x) for x in pn_notes['text']]\n",
    "print(note_len[1:5])\n",
    "pn_notes.iloc[[1,2,3,4,5],[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d42c3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admission_type\n",
       "EMERGENCY    5126\n",
       "URGENT        253\n",
       "Name: hadm_id, dtype: Int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note counts by admission type\n",
    "pn_notes.groupby('admission_type')['hadm_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43100ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write input Dictionary:  27605\n"
     ]
    }
   ],
   "source": [
    "def store_med_tags(df):\n",
    "    \n",
    "    import operator\n",
    "\n",
    "    tags_dict = {}\n",
    "    for row in df.itertuples():\n",
    "        tags = findall_med_tags(row.text)\n",
    "        if tags is not None:\n",
    "            for tag in tags:\n",
    "                temp_tag = str(tag)\n",
    "#                if len(tags) > 0 :\n",
    "#                    print('tag: ',tags)\n",
    "                if temp_tag in tags_dict.keys():\n",
    "                    tags_dict[temp_tag] += 1\n",
    "                else:\n",
    "                    tags_dict[temp_tag] = 1\n",
    "    \n",
    "    sorted_d = dict( sorted(tags_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "#    print('Dictionary in descending order by value : ',len(sorted_d))\n",
    "     \n",
    "    return sorted_d\n",
    "#    return sorted_d\n",
    "\n",
    "\n",
    "def findall_med_tags(note_data):\n",
    "\n",
    "# https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/\n",
    "    #print('in data length: ', len(note_data))\n",
    "    \n",
    "    regex2 = r\"(\\[(.+?)\\])\"\n",
    "    \n",
    "#    note_data = re.sub(r'\\[.*?:.*?\\]', ' ', note_data)\n",
    "#    note_data = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', ' ', note_data)\n",
    "#    note_data = re.sub(r'\\s{2,99}', ' ', note_data)\n",
    "#    note_data = re.sub(r'\\n', ' ', note_data)\n",
    "#    note_data = re.sub(regex, ' ', note_data)\n",
    "#    note_data = note_data.upper()\n",
    "    tags= re.findall(regex2, note_data)\n",
    "    \n",
    "#    if len(tags) > 0 :\n",
    "#        print('tag length: ', len(tags))\n",
    "#        print('tags:\\n ', tags)\n",
    "        \n",
    "    return tags\n",
    "\n",
    "\n",
    "def write_dict_csv(outfile, adict):\n",
    "\n",
    "    \n",
    "    import csv\n",
    "    print('Write input Dictionary: ',len(adict.keys()))\n",
    "    field_names = ['word','count']\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(outfile, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for key in adict:\n",
    "#            if adict[key] > 300:\n",
    "            writer.writerow({'word': key, 'count': adict[key]})\n",
    "    csvfile.close()   \n",
    "    return\n",
    "    \n",
    "file2 = path + 'big_notes_tags_4-7-23.csv'\n",
    "adict = store_med_tags(pn_notes)\n",
    "if adict is not None:\n",
    "    write_dict_csv(file2, adict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b48c9580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine to remove unneccessary characters\n",
    "import re\n",
    "\n",
    "def preprocess1(x):\n",
    "    \n",
    "#    print('in2a: ', 'x length ', len(x),  '', x[0:20])\n",
    "    y = re.sub('\\\\[(.*?)\\\\]', '', x)\n",
    "#    print('in2b: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('[0-9]+\\.', '', y)  # remove 1.2. since the segmenter segments based on this\n",
    "#    print('in2c: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('dr\\.', 'doctor', y)\n",
    "#    print('in2d: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('m\\.d\\.', 'md', y)\n",
    "#    print('in2e: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('admission date:', '', y)\n",
    "#    print('in2f: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('discharge date:', '', y)\n",
    "#    print('in2g: ', 'y length ', len(y),  '', y[0:20])\n",
    "    y = re.sub('--|__|==', ' ', y)\n",
    "#   remove punctuation   -- new change 11/16/2024\n",
    "    y = re.sub(r'[^\\w\\s]', ' ', y)\n",
    "     # remove, digits, spaces\n",
    "#    print('in2h: ', 'y length ', len(y),  ' ', y[0:20])\n",
    "    y = y.translate(str.maketrans(\"\", \"\", string.digits))\n",
    "#    print('in2i: ', 'y length ', len(y),  ' ', y[0:20])\n",
    "    y = \" \".join(y.split())\n",
    "#    print('in2j: ', 'y length ', len(y),  ' ', y[0:20])\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75e18430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process each note, call above function, get rid of line feeds, and make lowercase\n",
    "from tqdm import tqdm, trange \n",
    "def preprocessing(df_less_n):\n",
    "#    print('in2: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].fillna(' ')\n",
    "#    print('in3: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].str.replace('\\n', ' ')\n",
    "#    print('in4: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].str.replace('\\r', ' ')\n",
    "#    print('in5: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].apply(str.strip)\n",
    "#    print('in6: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].str.lower()\n",
    "#    print('in7: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    df_less_n['text'] = df_less_n['text'].apply(lambda x: preprocess1(x))\n",
    "#    print('in8: ', 'df_less_n ', df_less_n.shape[0], ' ', df_less_n.iloc[0].text[0:20])\n",
    "    return df_less_n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aef62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subsequences(df_less_n):\n",
    "#to get 318 words chunks for readmission tasks\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    df_len = len(df_less_n)\n",
    "    want=pd.DataFrame({'hadm_id':[],'text':[],'icd10_code':[], 'category':[]})\n",
    "    \n",
    "    for i in tqdm(range(df_len)):\n",
    "        x=df_less_n.text.iloc[i].split()\n",
    "        n=int(len(x)/318)\n",
    "        for j in range(n):\n",
    "            #want=want.append({'TEXT':' '.join(x[j*318:(j+1)*318]),'Label':df_less_n.OUTPUT_LABEL.iloc[i],'ID':df_less_n.HADM_ID.iloc[i]},ignore_index=True)\n",
    "            temp_dict = {'text':' '.join(x[j*318:(j+1)*318]),'icd10_code':df_less_n.primary_icd10_code.iloc[i],\n",
    "                         'hadm_id':df_less_n.hadm_id.iloc[i], 'category':df_less_n.icd_category.iloc[i]}\n",
    "            want = pd.concat([want, pd.DataFrame(temp_dict, index=[0])], ignore_index=True)\n",
    "            \n",
    "        if len(x)%318>10:\n",
    "            #want=want.append({'TEXT':' '.join(x[-(len(x)%318):]),'Label':df_less_n.OUTPUT_LABEL.iloc[i],'ID':df_less_n.HADM_ID.iloc[i]},ignore_index=True)\n",
    "            temp_dict = {'text':' '.join(x[-(len(x)%318):]),'icd10_code':df_less_n.primary_icd10_code.iloc[i],\n",
    "                         'hadm_id':df_less_n.hadm_id.iloc[i], 'category':df_less_n.icd_category.iloc[i]}\n",
    "            want = pd.concat([want, pd.DataFrame(temp_dict, index=[0])], ignore_index=True)\n",
    "    \n",
    "    return want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ebaf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingb(df_less_n): \n",
    "    #print(df_less_n.columns)\n",
    "    df_less_n['text']=df_less_n['text'].fillna(' ')\n",
    "    df_less_n['text']=df_less_n['text'].str.replace('\\n',' ')\n",
    "    df_less_n['text']=df_less_n['text'].str.replace('\\r',' ')\n",
    "    df_less_n['text']=df_less_n['text'].apply(str.strip)\n",
    "    df_less_n['text']=df_less_n['text'].str.lower()\n",
    "\n",
    "    df_less_n['text']=df_less_n['text'].apply(lambda x: preprocess1(x))\n",
    "\n",
    "    #to get 318 words chunks for readmission tasks\n",
    "    #want = create_subsequences(df_less_n)\n",
    "    #return want\n",
    "    return(df_less_n[['hadm_id', 'text', 'primary_icd10_code', 'icd_category']]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b2569cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingc(df_less_n): \n",
    "    #print(df_less_n.columns)\n",
    "    df_less_n['text']=df_less_n['text'].fillna(' ')\n",
    "    df_less_n['text']=df_less_n['text'].str.replace('\\n',' ')\n",
    "    df_less_n['text']=df_less_n['text'].str.replace('\\r',' ')\n",
    "    df_less_n['text']=df_less_n['text'].apply(str.strip)\n",
    "    df_less_n['text']=df_less_n['text'].str.lower()\n",
    "\n",
    "    df_less_n['text']=df_less_n['text'].apply(lambda x: preprocess1(x))\n",
    "\n",
    "    #to get 318 words chunks for readmission tasks\n",
    "    #want = create_subsequences(df_less_n)\n",
    "    #return want\n",
    "    return(df_less_n[['hadm_id', 'text', 'primary_icd10_code', 'icd_category']]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b255efa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5379 5359 5379\n",
      "   hadm_id                                               text icd10_code  \\\n",
      "0   145834  micu progress nursing note patient arrived in ...      A41.9   \n",
      "1   143045  ccu npn s having cpain left l shoulder arm bac...     I25.10   \n",
      "\n",
      "  category  \n",
      "0    Blood  \n",
      "1    Heart  \n",
      "   hadm_id                                               text icd10_code  \\\n",
      "0   145834  date of birth sex m service medicine chief com...      A41.9   \n",
      "1   143045  date of birth sex f service cardiac surgery ch...     I25.10   \n",
      "\n",
      "  category  \n",
      "0    Blood  \n",
      "1    Heart  \n"
     ]
    }
   ],
   "source": [
    "# run preprocess for discharge and adm notes\n",
    "import string\n",
    "fdischarge_notes = preprocessingb(discharge_notes)\n",
    "fdischarge_notes.columns =  ['hadm_id', 'text', 'icd10_code', 'category']\n",
    "fpn_notes = preprocessingb(pn_notes)\n",
    "fpn_notes.columns =  ['hadm_id', 'text', 'icd10_code', 'category']\n",
    "# print first 2 texts columns in each dataset as a sanity check after cleanup\n",
    "full_fpn_notes = preprocessingc(pn_notes)\n",
    "full_fpn_notes.columns =  ['hadm_id', 'text', 'icd10_code', 'category']\n",
    "\n",
    "print(len(fpn_notes), len(fdischarge_notes), len(full_fpn_notes))\n",
    "print(fpn_notes[0:2])\n",
    "print(fdischarge_notes[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a526ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5379 5359 5379\n",
      "0    micu progress nursing note patient arrived in ...\n",
      "1    ccu npn s having cpain left l shoulder arm bac...\n",
      "Name: text, dtype: object\n",
      "0    date of birth sex m service medicine chief com...\n",
      "1    date of birth sex f service cardiac surgery ch...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(len(fpn_notes), len(fdischarge_notes), len(full_fpn_notes))\n",
    "print(fpn_notes[0:2].text[0:10])\n",
    "print(fdischarge_notes[0:2].text[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41ec0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Education/CCSU-Thesis-2024/Data/'\n",
    "f1name = 'pd_notes_cleanb.snappy3.parquet'\n",
    "f3name = 'full_pd_notes_cleanb.snappy3.parquet'\n",
    "f2name = 'discharge_notes_cleanb.snappy3.parquet'\n",
    "#fpn_notes.to_parquet(path + f1name,compression='snappy',index=None)  \n",
    "full_fpn_notes.to_parquet(path + f3name,compression='snappy',index=None)  \n",
    "#fdischarge_notes.to_parquet(path + f2name,compression='snappy',index=None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78789b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icd10_code\n",
      "A41.51     151\n",
      "A41.9      881\n",
      "I21.4      950\n",
      "I25.10    1216\n",
      "I34.0       74\n",
      "I35.2      155\n",
      "I50.23      92\n",
      "I50.9      301\n",
      "J18.9      324\n",
      "J69.0      348\n",
      "J96.00     625\n",
      "N17.9      262\n",
      "Name: hadm_id, dtype: int64\n",
      "icd10_code\n",
      "A41.51     151\n",
      "A41.9      881\n",
      "I21.4      950\n",
      "I25.10    1216\n",
      "I34.0       74\n",
      "I35.2      155\n",
      "I50.23      92\n",
      "I50.9      301\n",
      "J18.9      324\n",
      "J69.0      348\n",
      "J96.00     625\n",
      "N17.9      262\n",
      "Name: hadm_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fpn_notes.groupby('icd10_code')['hadm_id'].nunique())\n",
    "print(full_fpn_notes.groupby('icd10_code')['hadm_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d343bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os\n",
    "s3 = boto3.resource('s3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e267056",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = 'Data/' \n",
    "S3_path = subdir + f1name\n",
    "out_file = path + f1name\n",
    "s3.meta.client.upload_file(out_file, 'depratti-masters-thesis', S3_path)\n",
    "S3_path = subdir + f2name\n",
    "out_file = path + f2name\n",
    "s3.meta.client.upload_file(out_file, 'depratti-masters-thesis', S3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "298a56fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpn_notes shape:  (5379, 4)\n",
      "fpn_notes columns:  Index(['hadm_id', 'text', 'icd10_code', 'category'], dtype='object')\n",
      "full fpn_notes shape:  (5379, 4)\n",
      "full_fpn_notes columns:  Index(['hadm_id', 'text', 'icd10_code', 'category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('fpn_notes shape: ', fpn_notes.shape)\n",
    "print('fpn_notes columns: ', fpn_notes.columns)\n",
    "print('full fpn_notes shape: ', full_fpn_notes.shape)\n",
    "print('full_fpn_notes columns: ', full_fpn_notes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a26bd028",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Blood     1032\n",
      "Heart     2788\n",
      "Kidney     262\n",
      "Lungs     1297\n",
      "Name: hadm_id, dtype: Int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "icd10_code\n",
       "A41.9      881\n",
       "I21.4      950\n",
       "I25.10    1216\n",
       "I34.0       74\n",
       "I35.2      155\n",
       "I50.23      92\n",
       "I50.9      301\n",
       "J18.9      324\n",
       "J69.0      348\n",
       "J96.00     625\n",
       "N17.9      262\n",
       "Name: hadm_id, dtype: Int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fpn_notes.groupby('category')['hadm_id'].count())\n",
    "fpn_notes.groupby('icd10_code')['hadm_id'].count()[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81c9a47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icd10_code\n",
      "A41.51     151\n",
      "A41.9      881\n",
      "I21.4      950\n",
      "I25.10    1216\n",
      "I34.0       74\n",
      "I35.2      155\n",
      "I50.23      92\n",
      "I50.9      301\n",
      "J18.9      324\n",
      "J69.0      348\n",
      "J96.00     625\n",
      "N17.9      262\n",
      "Name: hadm_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fpn_notes.groupby('icd10_code')['hadm_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddd08070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5359 5359 5379 5379\n",
      "category\n",
      "Blood     1032\n",
      "Heart     2788\n",
      "Kidney     262\n",
      "Lungs     1297\n",
      "Name: hadm_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Blood     1032\n",
       "Heart     2788\n",
       "Kidney     262\n",
       "Lungs     1297\n",
       "Name: hadm_id, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(fdischarge_notes), len(fdischarge_notes.hadm_id.unique()), \n",
    "      len(fpn_notes), len(fpn_notes.hadm_id.unique()))\n",
    "print(fpn_notes.groupby('category')['hadm_id'].nunique())\n",
    "full_fpn_notes.groupby('category')['hadm_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc2210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research]",
   "language": "python",
   "name": "conda-env-research-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
